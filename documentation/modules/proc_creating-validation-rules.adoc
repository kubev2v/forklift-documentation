// Module included in the following assemblies:
//
// * documentation/doc-Migrating_your_virtual_machines/assemblies/assembly_advanced-migration-options.adoc

:_mod-docs-content-type: PROCEDURE
[id="proc_creating-validation-rules_{context}"]
= Creating validation rules

[role="_abstract"]
To ensure that your custom validation rules persist across pod restarts, scaling events, and {project-first} upgrades, deploy the rules by using a *ConfigMap* Custom Resource (CR). By default, the `Validation` service reads validation rules from a ConfigMap named `forklift-validation-config` in the `{namespace}` namespace. You can optionally customize the ConfigMap name by updating the `forklift-controller` CR.

[IMPORTANT]
====
* If you create a rule with the same _name_ as an existing rule, the `Validation` service performs an `OR` operation with the rules.
* If you create a rule that contradicts a default rule, the `Validation` service will not start.
====

Validation rules are based on VM attributes collected by the `Provider Inventory` service. The `Provider Inventory` service presents provider-specific VM properties as simplified attributes for the validation engine. You can then create Rego queries based on the attributes, and add the queries to the `ConfigMap` CR to apply validation rules across different source environments.

For example, in a validation rule that checks if a VMware VM has NUMA node affinity configured, you have these elements:

* VMware API path: `MOR:VirtualMachine.config.extraConfig["numa.nodeAffinity"]`.
* `Provider Inventory` service attribute with a list value:
+
[cols=",",options="header",]
|===
|Inventory Attribute
|Example Value
|`numa.nodeAffinity`
|`["True"]` or `[]` (empty list if not configured)
|===

* Rego query based on the attribute:
+
[source,terminal]
----
count(input.numaNodeAffinity) != 0
----
For information about Rego files, see xref:about-rego-files_{context}[About Rego files].

.Procedure

. Create a `ConfigMap` named `forklift-validation-config` in the `{namespace}` namespace:
+
[NOTE]
====
If you want to use a different ConfigMap name, you must also configure the `forklift-controller` CR. See the optional step below for details.
====
+
Example:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: forklift-validation-config
  namespace: {namespace}
data:
  vmware_multiple_disks.rego: |-
    package <provider_package> 

    has_multiple_disks { 
      count(input.disks) > 1
    }

    concerns[flag] {
      has_multiple_disks 
        flag := {
          "category": "<Information>", 
          "label": "Multiple disks detected",
          "assessment": "Multiple disks detected on this VM."
        }
    }
EOF
----
+
* `<provider_package>`: The provider package name. Valid values are `io.konveyor.forklift.vmware` for VMware and `io.konveyor.forklift.ovirt` for {rhv-full}.
* `count(input.disks)`: Your Rego query.
* `category`: Valid values are `Critical`, `Warning`, and `Information`.
. Optional: If you are using a custom ConfigMap name instead of the default `forklift-validation-config`, add the `validation_configmap_name` parameter to the `spec` section of the `ForkliftController` CR:
+
[source,yaml]
----
spec:
  ...
  validation_configmap_name: <custom_configmap_name>
  ...
----
+
* Replace `<custom_configmap_name>` with the name of your ConfigMap.
. Stop the `Validation` pod by scaling the `forklift-validation` deployment to `0`:
+
[source,terminal,subs="attributes+"]
----
$ {oc} scale -n {namespace} --replicas=0 deployment/forklift-validation
----
. Start the `Validation` pod by scaling the `forklift-validation` deployment to `1`:
+
[source,terminal,subs="attributes+"]
----
$ {oc} scale -n {namespace} --replicas=1 deployment/forklift-validation
----
. Check the `Validation` pod log to verify that the pod started:
+
[source,terminal,subs="attributes+"]
----
$ {oc} logs -f <validation_pod>
----
+
If the custom rule conflicts with a default rule, the `Validation` pod does not start.
. Remove the source provider:
+
[source,terminal,subs="attributes+"]
----
$ {oc} delete provider <provider> -n {namespace}
----
. Add the source provider to apply the new rule. For information about adding a source provider, see the sections about adding a source provider in Chapters 10-14 of link:https://docs.redhat.com/en/documentation/migration_toolkit_for_virtualization/2.10/html/planning_your_migration_to_red_hat_openshift_virtualization/assembly_planning-migration-vmware_mtv[_Planning your migration to Red Hat OpenShift Virtualization_]:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <provider>
  namespace: {namespace}
spec:
  type: <provider_type> 
  url: <api_end_point> 
  secret:
    name: <secret> 
    namespace: {namespace}
EOF
----
+
* `<provider_type>`: Valid values are `ovirt`, `vsphere`, and `openstack`.
* `<api_end_point>`: The API endpoint URL, for example, `https://<vCenter_host>/sdk` for vSphere, `https://<engine_host>/ovirt-engine/api` for {rhv-short}, or `https://<identity_service>/v3` for {osp}.
* `<secret>`: The name of the provider `Secret` CR.
.Next step

Update the inventory rules version after creating a custom rule so that the `Provider Inventory` service detects the changes and validates the VMs. For more information, see xref:updating-inventory-rules-version_{context}[Updating the inventory rules version].

