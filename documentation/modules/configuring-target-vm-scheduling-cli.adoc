// Module included in the following assemblies:
//
// * documentation/doc-Migration_Toolkit_for_Virtualization/master.adoc

:_content-type: PROCEDURE
[id="configuring-target-vm-scheduling-cli_{context}"]
= Scheduling target VMs from the command-line interface

[role="_abstract"]
You can use the command-line interface (CLI) to tell {project-first} to migrate virtual machines (VMs) to specific nodes or workloads (pods) of {virt} as well as to schedule when the VMs are powered on.

The {project-short} CLI supports the following scheduling-related labels, all of which are added to the `Plan` CR:

- `targetAffinity`: Implements placement policies such as co-locating related workloads or, for disaster recovery, ensuring that specific VMs are migrated to different nodes. This type of label uses hard (requirements) and soft (preferences) conditions combined with logical operators, such as `and`, `or,` and `not`, to provide greater flexibility than the `targetLabelSelector` label discussed following. 
- `targetLabels`: Applies organizational or operational labels to migrated VMs for identification and management.
- `targetNodeSelector`: Ensures VMs are scheduled on nodes that are an exact match for key-value pairs you create. This type of label is often used for nodes with special capabilities, such as GPU nodes or storage nodes.

[IMPORTANT]
====
System-managed labels, such as migration, plan, VM ID, or application labels, override any user-defined labels.
====

.Prerequisites

Migrations that use target VM scheduling require the following prerequisites, in addition to the prerequisites for your source provider:

* {project-first} 2.10 or later.
* Version of {virt} that is compatible with your version of {project-short}. For {project-short} 2.10, the compatible versions of {virt} are 4.18, 4.19, and 4.20 only.
* `cluster-admin` or equivalent security privileges that allow managing `VirtualMachineInstance` objects and associated Kubernetes scheduling primitives.

.Procedure

. Create custom resources (CR)s for the migration according to the procedure for the provider.
. In the `Plan` CR, add the following labels before `spec:targetNamespace`. All are optional.
+
[source,yaml,subs="attributes+"]
...
  targetAffinity: <affinity rule, which can be quite complex, is entered in lines following this label. See example that follows>
  targetLabels:
    label: <label>
  targetNodeSelector:
    <key>:<value>
  targetNamespace:<target_namespace>
... 
+
Example:
+
The following scheduling rule migrates the VMs in the plan to different nodes for disaster recovery:
[source,yaml,subs="attributes+"]
----
  targetLabels:
    label: test1
  targetAffinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: label
                operator: In
                values:
                  - test1
          topologyKey: kubernetes.io/hostname
----

.Result

As a result of the preceding rule, the VMs are migrated accordingly to the resulting `spec`:

[source,yaml,subs="attributes+"]
----
spec:
  runStrategy: Always
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mtv-rhel8-sanity-ceph-rbd
        label: test1
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: label
                    operator: In
                    values:
                      - test1
              topologyKey: kubernetes.io/hostname
----


